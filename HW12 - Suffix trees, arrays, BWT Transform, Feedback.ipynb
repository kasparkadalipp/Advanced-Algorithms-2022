{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Submitted by: Kaspar Kadalipp </font>\n",
    "# HW12. Suffix trees/arrays, Peer review, Feedback, TSP competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'> Less important code is placed here</font>\n",
    "### <font color='orange'> Report is below </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "inf = float('inf')\n",
    "\n",
    "def euclideanDistance(node1, node2):\n",
    "    x1, y1 = node1\n",
    "    x2, y2 = node2\n",
    "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "# from https://github.com/Retsediv/ChristofidesAlgorithm\n",
    "def tsp(data):\n",
    "    G = build_graph(data)\n",
    "    MSTree = minimum_spanning_tree(G)\n",
    "    odd_vertexes = find_odd_vertexes(MSTree)\n",
    "    minimum_weight_matching(MSTree, G, odd_vertexes)\n",
    "    eulerian_tour = find_eulerian_tour(MSTree, G)\n",
    "\n",
    "    current = eulerian_tour[0]\n",
    "    path = [current]\n",
    "    visited = [False] * len(eulerian_tour)\n",
    "    visited[eulerian_tour[0]] = True\n",
    "    length = 0\n",
    "\n",
    "    for v in eulerian_tour:\n",
    "        if not visited[v]:\n",
    "            path.append(v)\n",
    "            visited[v] = True\n",
    "\n",
    "            length += G[current][v]\n",
    "            current = v\n",
    "\n",
    "    length += G[current][eulerian_tour[0]]\n",
    "    return path, length\n",
    "\n",
    "\n",
    "def get_length(x1, y1, x2, y2):\n",
    "    return ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** (1.0 / 2.0)\n",
    "\n",
    "\n",
    "def build_graph(data):\n",
    "    graph = {}\n",
    "    for this in range(len(data)):\n",
    "        for another_point in range(len(data)):\n",
    "            if this != another_point:\n",
    "                if this not in graph:\n",
    "                    graph[this] = {}\n",
    "                graph[this][another_point] = get_length(data[this][0], data[this][1], data[another_point][0],data[another_point][1])\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "class UnionFind:\n",
    "    def __init__(self):\n",
    "        self.weights = {}\n",
    "        self.parents = {}\n",
    "\n",
    "    def __getitem__(self, object):\n",
    "        if object not in self.parents:\n",
    "            self.parents[object] = object\n",
    "            self.weights[object] = 1\n",
    "            return object\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [object]\n",
    "        root = self.parents[object]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.parents)\n",
    "\n",
    "    def union(self, *objects):\n",
    "        roots = [self[x] for x in objects]\n",
    "        heaviest = max([(self.weights[r], r) for r in roots])[1]\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest\n",
    "\n",
    "\n",
    "def minimum_spanning_tree(G):\n",
    "    tree = []\n",
    "    subtrees = UnionFind()\n",
    "    for W, u, v in sorted((G[u][v], u, v) for u in G for v in G[u]):\n",
    "        if subtrees[u] != subtrees[v]:\n",
    "            tree.append((u, v, W))\n",
    "            subtrees.union(u, v)\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "def find_odd_vertexes(MST):\n",
    "    tmp_g = {}\n",
    "    vertexes = []\n",
    "    for edge in MST:\n",
    "        if edge[0] not in tmp_g:\n",
    "            tmp_g[edge[0]] = 0\n",
    "\n",
    "        if edge[1] not in tmp_g:\n",
    "            tmp_g[edge[1]] = 0\n",
    "\n",
    "        tmp_g[edge[0]] += 1\n",
    "        tmp_g[edge[1]] += 1\n",
    "\n",
    "    for vertex in tmp_g:\n",
    "        if tmp_g[vertex] % 2 == 1:\n",
    "            vertexes.append(vertex)\n",
    "\n",
    "    return vertexes\n",
    "\n",
    "\n",
    "def minimum_weight_matching(MST, G, odd_vert):\n",
    "    import random\n",
    "    random.shuffle(odd_vert)\n",
    "\n",
    "    while odd_vert:\n",
    "        v = odd_vert.pop()\n",
    "        length = float(\"inf\")\n",
    "        u = 1\n",
    "        closest = 0\n",
    "        for u in odd_vert:\n",
    "            if v != u and G[v][u] < length:\n",
    "                length = G[v][u]\n",
    "                closest = u\n",
    "\n",
    "        MST.append((v, closest, length))\n",
    "        odd_vert.remove(closest)\n",
    "\n",
    "\n",
    "def find_eulerian_tour(MatchedMSTree, G):\n",
    "    # find neigbours\n",
    "    neighbours = {}\n",
    "    for edge in MatchedMSTree:\n",
    "        if edge[0] not in neighbours:\n",
    "            neighbours[edge[0]] = []\n",
    "\n",
    "        if edge[1] not in neighbours:\n",
    "            neighbours[edge[1]] = []\n",
    "\n",
    "        neighbours[edge[0]].append(edge[1])\n",
    "        neighbours[edge[1]].append(edge[0])\n",
    "\n",
    "    # print(\"Neighbours: \", neighbours)\n",
    "\n",
    "    # finds the hamiltonian circuit\n",
    "    start_vertex = MatchedMSTree[0][0]\n",
    "    EP = [neighbours[start_vertex][0]]\n",
    "\n",
    "    while len(MatchedMSTree) > 0:\n",
    "        for i, v in enumerate(EP):\n",
    "            if len(neighbours[v]) > 0:\n",
    "                break\n",
    "\n",
    "        while len(neighbours[v]) > 0:\n",
    "            w = neighbours[v][0]\n",
    "\n",
    "            remove_edge_from_matchedMST(MatchedMSTree, v, w)\n",
    "\n",
    "            del neighbours[v][(neighbours[v].index(w))]\n",
    "            del neighbours[w][(neighbours[w].index(v))]\n",
    "\n",
    "            i += 1\n",
    "            EP.insert(i, w)\n",
    "            v = w\n",
    "\n",
    "    return EP\n",
    "\n",
    "\n",
    "def remove_edge_from_matchedMST(MatchedMST, v1, v2):\n",
    "    for i, item in enumerate(MatchedMST):\n",
    "        if (item[0] == v2 and item[1] == v1) or (item[0] == v1 and item[1] == v2):\n",
    "            del MatchedMST[i]\n",
    "    return MatchedMST\n",
    "\n",
    "def path_improvement(distance_matrix, vertices, prev_path, prev_distance):\n",
    "    best_path = prev_path\n",
    "    best_distance = prev_distance\n",
    "    while True:\n",
    "        prev_best = best_distance\n",
    "        for i in range(len(prev_path)):\n",
    "            for j in range(len(prev_path)):\n",
    "                path = best_path[:]\n",
    "                path[i], path[j] = path[j], path[i]\n",
    "                distance = 0\n",
    "                for k in range(1, len(path)):\n",
    "                    distance += distance_matrix[path[k - 1]][path[k]][0]\n",
    "                distance += euclideanDistance(vertices[path[0]], vertices[path[-1]])\n",
    "                if distance < best_distance:\n",
    "                    best_path = path\n",
    "                    best_distance = distance\n",
    "        if best_distance == prev_best:\n",
    "            break\n",
    "    return best_path, best_distance\n",
    "\n",
    "# https://codereview.stackexchange.com/questions/208387/2-opt-algorithm-for-the-traveling-salesman-and-or-sro\n",
    "def two_opt(cost_mat, route, vertices):\n",
    "    improved = True\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for i in range(1, len(route) - 2):\n",
    "            for j in range(i + 1, len(route)):\n",
    "                if j - i == 1:\n",
    "                    continue  # changes nothing, skip then\n",
    "                new_route = route[:]    # Creates a copy of route\n",
    "                new_route[i:j] = route[j - 1:i - 1:-1]  # this is the 2-optSwap since j >= i we use -1\n",
    "                c = cost(cost_mat, new_route, vertices)\n",
    "                if c < cost(cost_mat, route, vertices):\n",
    "                    route = new_route    # change current route to best\n",
    "                    if c < 24800:\n",
    "                        print(\"Improved to:\", c)\n",
    "                    improved = True\n",
    "    return route, cost(cost_mat, route, vertices)\n",
    "\n",
    "def cost(distance_matrix, path, vertices):\n",
    "    distance = 0\n",
    "    for k in range(1, len(path)):\n",
    "        distance += distance_matrix[path[k - 1]][path[k]][0]\n",
    "    distance += euclideanDistance(vertices[path[0]], vertices[path[-1]])\n",
    "    return distance\n",
    "\n",
    "def ex6(size):\n",
    "    with open(f'{size}.txt', 'r') as f:\n",
    "        vertices = [tuple(int(val) for val in line.strip().split(\" \")) for line in f.readlines()]\n",
    "        distance_matrix = [[0 for col in range(len(vertices))] for row in range(len(vertices))]\n",
    "        for row in range(len(vertices)):\n",
    "            for col in range(row, len(vertices)):\n",
    "                ed = euclideanDistance(vertices[row], vertices[col])\n",
    "                distance_matrix[row][col] = (ed, col)\n",
    "                distance_matrix[col][row] = (ed, row)\n",
    "\n",
    "        path, length = tsp(vertices)\n",
    "        print(f'Christofides algorithm distance: {length:.2f}')\n",
    "        path, length = two_opt(distance_matrix, path, vertices)\n",
    "        print(f'Distance after 2-opt improvement: {length:.2f}') # 25704.24\n",
    "        with open(f'{size}_optimised.txt', 'w+') as f:\n",
    "            for index in path:\n",
    "                f.write(f'{index}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX1 Peer review the first article assigned to you.\n",
    "\n",
    "#### reviewed student B47904 ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX2 Peer review the second article assigned to you.\n",
    "\n",
    "#### reviewed student B53231 ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX3\n",
    "\n",
    "##### You are given word: sinsinati.\n",
    "\n",
    "##### What are all the suffixes for the given word? Build a Suffix Trie and a Tree for the same word. Demonstrate searching for pattern \"sina\" using these data structures. Make sure to describe the algorithms you used to perform these tasks. What is a Suffix Trie/Tree be used for? What is the task of full-text indexing? What are the differences between using Tree instead of Trie?\n",
    "\n",
    "##### Take the same word and instead build a Suffix Array. Describe the algorithm. How could you use this suffix array to perform some operations? Where should we use Suffix Arrays instead of Suffix trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All suffixes:\n",
    "- sinsinati\n",
    "- insinati\n",
    "- nsinati\n",
    "- sinati\n",
    "- inati\n",
    "- nati\n",
    "- ati\n",
    "- ti\n",
    "- i\n",
    "\n",
    "\n",
    "Trie construction starts by iterating through characters of the text.\n",
    "It first builds trie $T_1$ using 1st character, then $T_2$ using 2nd character, then $T_3$ using 3rd character, …, $T_m$ using m-th character.\n",
    "Suffix trie $T_{i+1}$ is built on top of suffix tree $T_i$ by extending leaf nodes to be sure the suffix is in the trie.\n",
    "\n",
    "Suffix tree is very similar to trie, here all nodes with one child are simply merged with their parents.\n",
    "\n",
    "Suffix trie/tree are used to find occurrences of a pattern in a string. By preprocessing the text in $O(n)$ time a pattern can be found in $O(m)$ complexity, where $m$ is the length of the pattern and $n$ length of the text.\n",
    "Also, they can be used for finding the longest repeated substring, the longest common substring, the longest palindrome.\n",
    "\n",
    "Full-text indexing builds a data structure from the text which allows to efficiently find patterns. It splits the pattern searching into two phases, counting the number of pattern occurrences and locating their positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suffix array is gotten from sorting all suffixes of a string alphabetically and remembering the starting positions of these sorted suffixes.\n",
    "\n",
    "\n",
    "Suffix arrays take less space than suffix trees and any suffix tree algorithm can be replaced with an algorithm that uses a suffix array enhanced with additional information.\n",
    "\n",
    "The suffix array of a string can be used as an index to quickly locate every occurrence of a substring pattern P within the string S. Finding every occurrence of the pattern is equivalent to finding every suffix that begins with the substring. Thanks to the lexicographical ordering, these suffixes will be grouped together in the suffix array and can be found efficiently with two binary searches. The first search locates the starting position of the interval, and the second one determines the end position:\n",
    "\n",
    "\n",
    "<font color=\"gray\" >used resource: https://en.wikipedia.org/wiki/Suffix_array </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex3](https://i.imgur.com/P2nbFHL.png)\n",
    "![searching pattern](https://i.imgur.com/WM3zXUO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EX4\n",
    "\n",
    "##### Substring matching. Given two strings S1 and S2, and a positive integer k, find the number of substrings of S1 of length at least k that occur in S2. Develop and analyze an algorithm to solve this problem in O(|S1| + |S2| + sort(Σ)) time, where Σ is the alphabet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can solve this problem in O(|S1| + |S2| + sort(Σ)) time using a suffix array. The suffix array is a data structure that stores all the suffixes of a given string in an array. We can then use this array to search for substrings of S1 of length at least k that occur in S2.\n",
    "\n",
    "To begin, we create a suffix array for S1 and S2. We then traverse through the suffix array, and for each suffix of S1, we search for it in S2. If the suffix of S1 is found in S2, we check to see if its length is at least k. If so, we increment a counter. We repeat this process for all suffixes of S1 and S2.\n",
    "\n",
    "The resulting algorithm runs in O(|S1| + |S2| + sort(Σ)) time, since we need to construct the suffix array, which takes O(|S1| + sort(Σ)) time, and then traverse through the suffix array, which takes O(|S2|) time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX5\n",
    "\n",
    "##### Perform Burrows-Wheeler Transform on the following string: CGGTCGCT$. Make sure to draw the matrix. Demonstrate how you can reconstruct the original string from BWT. Where and why is BWT used? This <a href=\"https://www.youtube.com/watch?v=P3ORBMon8aw\">video</a> might help you get started:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Burrows–Wheeler transform is useful for lossless compression since it restructures data in such a way that the transformed text is more compressible. The transformation is reversible, without needing to store any additional data except the position of the first original character. The algorithm can be implemented efficiently using a suffix array thus reaching linear time complexity.\n",
    "\n",
    "It has applications in image compression and compression of genomic databases. It's also used in genetics sequence alignment and for sequence prediction in machine learning models.\n",
    "\n",
    "\n",
    "<font color=\"gray\" >used resource: https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex6.1](https://i.imgur.com/FZFnvjj.png)\n",
    "![ex6.2](https://i.imgur.com/CUpPzRF.png)\n",
    "![ex6.3](https://i.imgur.com/9kDWjZb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX6\n",
    "\n",
    "##### As was promised, the last task is from optimization homework, now we have small competition. Your task is to optimize 1024-city case as well as possible. Data is here: <a href=\"https://courses.cs.ut.ee/MTAT.03.238/2022_fall/uploads/Main/1024.txt\">1024-city-case</a>.\n",
    "\n",
    "##### An additional rule is that when you are exporting the image using <a href=\"https://abercus.github.io/tspvis/\">web tool</a>, the label in \"Path legal:False\", must be True! This confirms that every city has been visited exactly once.\n",
    "\n",
    "##### Report the best solutions (state-of-the-art) to the Piazza in a public thread, to initialize the competition. In the post describe your approach, report the calculation time, obtained path length and the visualization of the resulting path. The ones who can beat past best solutions will get points (even if someone will outcompete your solution next). To get points to make sure to post new best solutions to corresponding Piazza thread. NB! For the solution to beat previous solutions, it should have either a shorter resulting path or if lengths are comparable the new solution should be considerably faster.\n",
    "\n",
    "##### Also, very good descriptions of the approach and convergence rates - may get awarded with points upon TA decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christofides algorithm:\n",
    "1. Find MST T of graph\n",
    "2. Isolate set of odd-degree vertices S\n",
    "3. Find min weight perfect matching M of S\n",
    "4. Combine T and M into graph G\n",
    "5. Generate Eulerian tour of G\n",
    "6. Generate TSP tour from Eulerian tour\n",
    "\n",
    "I used Christofides algorithm that guarantees a solution withing a factor of 1.5 of the optimal solution. On average it should give a solution within a factor of 1.1 of the optimal solution.\n",
    "\n",
    "I further improve the solution of the Christofides algorithm by applying 2-opt improvement.\n",
    "\n",
    "Best distance: 24186.0089 - time: 10min 14sec\n",
    "\n",
    "![TSP](https://i.imgur.com/nAMeoeO.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christofides algorithm distance: 27708.29\n",
      "Improved to: 24797.35107218375\n",
      "Improved to: 24779.379317813004\n",
      "Improved to: 24718.317174707747\n",
      "Improved to: 24717.381772840836\n",
      "Improved to: 24683.540935570203\n",
      "Improved to: 24682.019364361488\n",
      "Improved to: 24661.77178175191\n",
      "Improved to: 24653.52272690139\n",
      "Improved to: 24632.148271465612\n",
      "Improved to: 24618.922510024113\n",
      "Improved to: 24613.86029036457\n",
      "Improved to: 24610.389473547923\n",
      "Improved to: 24601.52598642358\n",
      "Improved to: 24593.321398308533\n",
      "Improved to: 24585.75215392414\n",
      "Improved to: 24585.142175368466\n",
      "Improved to: 24582.11912235698\n",
      "Improved to: 24574.789127704073\n",
      "Improved to: 24565.520276756662\n",
      "Improved to: 24530.099988980877\n",
      "Improved to: 24529.407537394854\n",
      "Distance after 2-opt improvement: 24529.41\n",
      "CPU times: total: 4min 53s\n",
      "Wall time: 7min 53s\n"
     ]
    }
   ],
   "source": [
    "%time ex6(1024)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web tool path: [261, 389, 567, 763, 538, 87, 517, 390, 906, 36, 485, 745, 197, 5, 977, 965, 343, 778, 9, 370, 100, 557, 624, 675, 558, 484, 929, 649, 112, 142, 199, 835, 855, 556, 42, 724, 917, 516, 616, 258, 868, 938, 543, 688, 60, 1001, 714, 183, 63, 881, 48, 75, 705, 473, 904, 427, 1006, 487, 927, 509, 372, 1008, 59, 1023, 746, 431, 298, 14, 952, 876, 62, 302, 986, 577, 385, 646, 514, 555, 535, 489, 578, 283, 359, 407, 598, 404, 709, 411, 829, 73, 180, 505, 807, 228, 209, 523, 171, 1021, 381, 811, 249, 222, 542, 802, 115, 46, 813, 963, 163, 568, 305, 823, 354, 680, 685, 153, 405, 551, 597, 659, 104, 937, 378, 281, 424, 861, 884, 384, 920, 98, 471, 376, 645, 901, 203, 968, 573, 232, 114, 337, 461, 272, 909, 239, 150, 130, 394, 790, 167, 981, 276, 525, 103, 235, 441, 704, 65, 653, 698, 784, 367, 759, 983, 949, 928, 534, 622, 102, 89, 362, 17, 738, 1016, 156, 632, 216, 123, 12, 117, 791, 193, 419, 678, 361, 830, 278, 457, 833, 639, 292, 503, 301, 311, 549, 334, 593, 437, 493, 455, 469, 346, 251, 627, 1004, 733, 160, 23, 477, 782, 936, 459, 192, 295, 386, 85, 518, 118, 44, 39, 978, 425, 841, 155, 751, 41, 480, 661, 850, 352, 582, 240, 339, 594, 693, 502, 866, 750, 565, 347, 606, 587, 220, 766, 467, 583, 287, 654, 526, 947, 442, 721, 77, 748, 717, 716, 942, 891, 519, 959, 184, 279, 506, 805, 297, 599, 450, 398, 174, 141, 718, 364, 300, 151, 808, 447, 933, 128, 662, 974, 870, 323, 11, 45, 290, 922, 231, 827, 262, 762, 374, 18, 61, 719, 417, 903, 743, 10, 189, 532, 744, 472, 105, 1019, 1022, 1011, 76, 574, 843, 429, 727, 316, 315, 268, 499, 546, 70, 595, 229, 507, 798, 756, 896, 58, 863, 309, 265, 679, 7, 586, 191, 900, 440, 109, 956, 331, 94, 274, 122, 54, 736, 1010, 998, 233, 412, 121, 463, 476, 676, 647, 809, 607, 640, 241, 217, 202, 621, 629, 847, 652, 428, 681, 177, 934, 78, 666, 663, 227, 207, 911, 851, 162, 492, 351, 734, 908, 707, 420, 691, 562, 754, 80, 794, 964, 69, 93, 168, 877, 559, 839, 561, 16, 195, 226, 182, 188, 864, 86, 40, 826, 554, 52, 205, 566, 993, 838, 320, 973, 992, 682, 125, 610, 584, 131, 332, 71, 438, 391, 496, 277, 569, 648, 545, 19, 326, 344, 737, 697, 500, 779, 776, 987, 795, 923, 783, 872, 379, 710, 804, 939, 399, 831, 919, 366, 617, 512, 824, 529, 925, 777, 822, 414, 55, 967, 165, 402, 846, 215, 1000, 603, 400, 416, 1018, 612, 749, 147, 885, 1009, 687, 1017, 494, 656, 436, 341, 667, 895, 628, 600, 317, 175, 642, 953, 38, 84, 254, 371, 537, 955, 836, 173, 413, 999, 941, 672, 126, 26, 887, 113, 625, 913, 611, 706, 164, 53, 820, 984, 497, 571, 2, 393, 774, 1020, 375, 408, 135, 158, 969, 358, 196, 4, 615, 380, 643, 270, 194, 740, 780, 875, 206, 449, 579, 980, 572, 753, 149, 237, 234, 781, 355, 13, 422, 330, 944, 854, 403, 242, 285, 488, 306, 252, 899, 475, 801, 120, 1007, 741, 458, 576, 619, 914, 972, 350, 760, 225, 510, 668, 761, 27, 64, 858, 985, 329, 348, 848, 482, 521, 101, 960, 319, 68, 796, 145, 303, 860, 591, 388, 520, 134, 880, 169, 29, 90, 324, 267, 418, 596, 35, 137, 633, 318, 637, 97, 690, 528, 764, 815, 498, 547, 1003, 335, 291, 812, 127, 912, 623, 307, 430, 857, 238, 533, 604, 580, 462, 67, 671, 478, 204, 994, 243, 322, 146, 187, 935, 788, 739, 377, 396, 726, 962, 282, 453, 95, 650, 256, 1013, 589, 166, 296, 886, 677, 223, 575, 951, 230, 609, 313, 536, 439, 989, 865, 686, 24, 602, 957, 773, 132, 454, 684, 585, 699, 152, 211, 531, 581, 119, 479, 470, 608, 988, 852, 797, 200, 365, 961, 844, 722, 660, 333, 280, 1, 631, 433, 890, 871, 874, 110, 181, 266, 464, 210, 996, 564, 630, 665, 392, 443, 483, 336, 294, 490, 136, 260, 905, 360, 312, 641, 862, 501, 37, 674, 426, 170, 159, 504, 635, 269, 82, 255, 634, 747, 834, 703, 460, 975, 950, 289, 601, 859, 275, 288, 814, 966, 363, 849, 873, 742, 816, 423, 221, 732, 785, 800, 286, 106, 212, 837, 452, 293, 883, 930, 349, 1012, 626, 825, 271, 915, 728, 34, 190, 673, 902, 435, 560, 74, 771, 752, 474, 144, 83, 56, 867, 828, 382, 432, 22, 395, 700, 328, 185, 696, 28, 468, 111, 971, 31, 940, 201, 775, 948, 495, 99, 540, 96, 129, 224, 793, 713, 176, 368, 882, 563, 508, 79, 670, 72, 720, 451, 765, 898, 997, 926, 644, 530, 550, 708, 767, 466, 401, 47, 345, 618, 548, 853, 373, 406, 273, 257, 208, 731, 527, 353, 757, 253, 30, 588, 907, 723, 715, 369, 116, 179, 138, 821, 711, 421, 976, 21, 491, 888, 735, 51, 148, 892, 486, 43, 92, 1005, 465, 590, 213, 481, 20, 250, 918, 931, 340, 157, 878, 970, 638, 91, 397, 1002, 921, 236, 314, 33, 3, 524, 246, 991, 958, 259, 786, 133, 729, 842, 218, 178, 172, 712, 893, 456, 544, 415, 284, 446, 772, 768, 799, 8, 702, 945, 342, 338, 592, 725, 304, 570, 787, 620, 409, 299, 651, 689, 758, 539, 613, 840, 810, 25, 57, 701, 792, 88, 932, 515, 444, 658, 916, 979, 15, 657, 692, 321, 614, 6, 410, 845, 818, 219, 856, 310, 245, 186, 669, 387, 448, 946, 1014, 327, 513, 244, 552, 605, 356, 803, 995, 894, 789, 511, 683, 143, 819, 695, 357, 308, 32, 541, 1015, 325, 161, 553, 636, 81, 770, 897, 107, 769, 49, 434, 954, 247, 924, 664, 817, 889, 263, 910, 248, 694, 730, 655, 806, 124, 832, 755, 869, 198, 383, 154, 522, 445, 264, 943, 879, 990, 108, 982, 0, 139, 50, 140, 66, 214]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX7\n",
    "\n",
    "#### Provide feedback for the course and homework topics so far\n",
    "\n",
    "##### which topics were most useful?\n",
    "\n",
    "Graphs (hw 8), dynamic programming (hw 10), NFA and regular expressions (hw 11)\n",
    "\n",
    "##### what needs to be covered better in the course?\n",
    "\n",
    "I think regular expressions deserves to be the main topic of a homework. There are ways to optimise matching, performance of different optimizations could be compared. Advanced regex syntax could also be introduced.\n",
    "\n",
    "##### are there some topics that would need more practical implementation assignments?\n",
    "\n",
    "Regular expressions\n",
    "\n",
    "##### are there some topics that got too much attention (e.g. too boring or otherwise already well known)\n",
    "\n",
    "None of the topics got too much attention in my opinion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
